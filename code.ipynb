{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "orders = pd.read_csv(r'orders.csv')\n",
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = pd.read_csv(r'order_products__prior.csv')\n",
    "prior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'order_products__train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_prior = pd.merge(prior,orders,on=['order_id','order_id'])\n",
    "order_prior = order_prior.sort_values(by=['user_id','order_id'])\n",
    "order_prior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(r'products.csv')\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisles = pd.read_csv(r'aisles.csv')\n",
    "aisles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mt = pd.merge(prior,products, on = ['product_id','product_id'])\n",
    "_mt = pd.merge(_mt,orders,on=['order_id','order_id'])\n",
    "mt = pd.merge(_mt,aisles,on=['aisle_id','aisle_id'])\n",
    "mt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt['product_name'].value_counts()[0:10]\n",
    "len(mt['product_name'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fresh fruits and fresh vegetables are the best selling goods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt['aisle'].value_counts()[0:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ths first thing to do is creating a dataframe with all the purchases made by each user.The resulting 'cust_prod' DataFrame will have 'user_id' as its index and 'aisle' as its columns, with the values being the frequency counts of each combination of 'user_id' and 'aisle'. In other words, it shows how many times each user has purchased products from each aisle.This type of analysis can be useful in understanding customer behavior and preferences, as well as identifying popular products and categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prod = pd.crosstab(mt['user_id'], mt['aisle'])\n",
    "cust_prod.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then execute a Principal Component Analysis to the obtained dataframe. This will reduce the number of features from the number of aisles to 6, the numbr of principal components I have chosen.The 'PCA' function is instantiated with the parameter 'n_components=6', which sets the number of principal components to 6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6)\n",
    "pca.fit(cust_prod)\n",
    "pca_samples = pca.transform(cust_prod)\n",
    "ps = pd.DataFrame(pca_samples)\n",
    "ps.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that the choice of which principal components to use for clustering can have a significant impact on the results, and there is no one \"correct\" choice. It's often a good idea to explore multiple combinations of principal components and clustering parameters to find the best approach for your specific dataset and problem.we tried a range of different combinations of principal components, such as (PC1, PC2), (PC3, PC4), or (PC1, PC3), and compared the resulting clustering performance using evaluation metrics and (PC4,PC1) pair is chosen as a suitable pair for k-mean clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "tocluster = pd.DataFrame(ps[[4,1]])\n",
    "print (tocluster.shape)\n",
    "print (tocluster.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(tocluster[4], tocluster[1], 'o', markersize=2, color='blue', alpha=0.5, label='class1')\n",
    "\n",
    "plt.xlabel('x_values')\n",
    "plt.ylabel('y_values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "clusterer = KMeans(n_clusters=4,random_state=42).fit(tocluster)\n",
    "centers = clusterer.cluster_centers_\n",
    "c_preds = clusterer.predict(tocluster)\n",
    "print(centers)\n",
    "\n",
    "print (c_preds[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "colors = ['orange','blue','purple','green']\n",
    "colored = [colors[k] for k in c_preds]\n",
    "print (colored[0:10])\n",
    "plt.scatter(tocluster[4],tocluster[1],  color = colored)\n",
    "for ci,c in enumerate(centers):\n",
    "    plt.plot(c[0], c[1], 'o', markersize=8, color='red', alpha=0.9, label=''+str(ci))\n",
    "\n",
    "plt.xlabel('x_values')\n",
    "plt.ylabel('y_values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'c_preds' array obtained from the KMeans algorithm in the previous code block is used to populate the 'cluster' column of the 'clust_prod' DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_prod = cust_prod.copy()\n",
    "clust_prod['cluster'] = c_preds\n",
    "\n",
    "clust_prod.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this line of code, we are first filtering the rows of the clust_prod DataFrame where the cluster column has a value of 0.This creates a new DataFrame that contains only the rows where the cluster column is equal to 0. Then, we drop the cluster column from this new DataFrame using the drop method.Finally, we calculate the mean of each column of this new DataFrame using the mean method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (clust_prod.shape)\n",
    "f,arr = plt.subplots(2,2,sharex=True,figsize=(15,15))\n",
    "\n",
    "c1_count = len(clust_prod[clust_prod['cluster']==0])\n",
    "\n",
    "c0 = clust_prod[clust_prod['cluster']==0].drop('cluster',axis=1).mean()\n",
    "arr[0,0].bar(range(len(clust_prod.drop('cluster',axis=1).columns)),c0)\n",
    "c1 = clust_prod[clust_prod['cluster']==1].drop('cluster',axis=1).mean()\n",
    "arr[0,1].bar(range(len(clust_prod.drop('cluster',axis=1).columns)),c1)\n",
    "c2 = clust_prod[clust_prod['cluster']==2].drop('cluster',axis=1).mean()\n",
    "arr[1,0].bar(range(len(clust_prod.drop('cluster',axis=1).columns)),c2)\n",
    "c3 = clust_prod[clust_prod['cluster']==3].drop('cluster',axis=1).mean()\n",
    "arr[1,1].bar(range(len(clust_prod.drop('cluster',axis=1).columns)),c3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out what are the top 10 goods bought by people of each cluster. We are going to rely first on the absolute data and then on a percentage among the top 8 products for each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0.sort_values(ascending=False)[0:10]\n",
    "\n",
    "c1.sort_values(ascending=False)[0:10]\n",
    "\n",
    "c2.sort_values(ascending=False)[0:10]\n",
    "\n",
    "c3.sort_values(ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "cluster_means = [[c0['fresh fruits'],c0['fresh vegetables'],c0['packaged vegetables fruits'], c0['yogurt'], c0['packaged cheese'], c0['milk'],c0['water seltzer sparkling water'],c0['chips pretzels']],\n",
    "                 [c1['fresh fruits'],c1['fresh vegetables'],c1['packaged vegetables fruits'], c1['yogurt'], c1['packaged cheese'], c1['milk'],c1['water seltzer sparkling water'],c1['chips pretzels']],\n",
    "                 [c2['fresh fruits'],c2['fresh vegetables'],c2['packaged vegetables fruits'], c2['yogurt'], c2['packaged cheese'], c2['milk'],c2['water seltzer sparkling water'],c2['chips pretzels']],\n",
    "                 [c3['fresh fruits'],c3['fresh vegetables'],c3['packaged vegetables fruits'], c3['yogurt'], c3['packaged cheese'], c3['milk'],c3['water seltzer sparkling water'],c3['chips pretzels']]]\n",
    "cluster_means = pd.DataFrame(cluster_means, columns = ['fresh fruits','fresh vegetables','packaged vegetables fruits','yogurt','packaged cheese','milk','water seltzer sparkling water','chips pretzels'])\n",
    "HTML(cluster_means.to_html())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table depicts the percentage these goods with respect to the other top 8 in each cluster. It is easy some interesting differences among the clusters.\n",
    "\n",
    "It seems people of cluster 1 buy more fresh vegetables than the other clusters. As shown by absolute data, Cluster 1 is also the cluster including those customers buying far more goods than any others.\n",
    "\n",
    "People of cluster 2 buy more yogurt than people of the other clusters.\n",
    "\n",
    "Absolute Data shows us People of cluster 3 buy a Lot of 'Baby Food Formula' which not even listed in the top 8 products but mainly characterize this cluster. Coherently (I think) with this observation they buy more milk than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_perc = cluster_means.iloc[:, :].apply(lambda x: (x / x.sum())*100,axis=1)\n",
    "HTML(cluster_perc.to_html())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
